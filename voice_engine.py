import streamlit as st
from gtts import gTTS
import io
import base64
import os

# --- NOV√â IMPORTY PRO AI A MIKROFON ---
# Zabaleno do try-except pro stabilitu, kdyby chybƒõly knihovny
try:
    import google.generativeai as genai
    from streamlit_mic_recorder import mic_recorder
    import speech_recognition as sr
except ImportError as e:
    st.error(f"‚ö†Ô∏è Chyb√≠ kritick√© moduly v voice_engine.py! ({e})")
    st.info("üí° ≈òe≈°en√≠: Spus≈• v termin√°lu: pip install google-generativeai streamlit-mic-recorder SpeechRecognition")
    st.stop()

# --- KONFIGURACE ---
VOICE_LANG = 'cs' 

# Pokus o naƒçten√≠ API kl√≠ƒçe
try:
    API_KEY = st.secrets.get("GOOGLE_API_KEY") or os.getenv("GOOGLE_API_KEY")
    if API_KEY:
        genai.configure(api_key=API_KEY)
    else:
        # Jen logujeme do konzole, nebudeme spamovat UI varov√°n√≠m hned po startu
        print("‚ö†Ô∏è VoiceEngine: Nen√≠ nastaven GOOGLE_API_KEY. AI funkce nepojedou.")
except Exception as e:
    print(f"‚ö†Ô∏è VoiceEngine Config Error: {e}")

class VoiceAssistant:
    """
    T≈ô√≠da pro spr√°vu hlasov√Ωch funkc√≠ aplikace.
    Obsahuje: TTS (Mluven√≠), STT (Poslouch√°n√≠), LLM (Gemini).
    """
    
    @staticmethod
    def speak(text):
        """
        P≈ôevede text na ≈ôeƒç a vr√°t√≠ HTML audio p≈ôehr√°vaƒç.
        """
        if not text:
            return None
            
        try:
            tts = gTTS(text=text, lang=VOICE_LANG, slow=False)
            audio_buffer = io.BytesIO()
            tts.write_to_fp(audio_buffer)
            audio_buffer.seek(0)
            
            audio_b64 = base64.b64encode(audio_buffer.read()).decode()
            audio_type = "audio/mp3"
            
            audio_html = f"""
                <audio autoplay="true" style="display:none;">
                    <source src="data:{audio_type};base64,{audio_b64}" type="{audio_type}">
                </audio>
            """
            return audio_html
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Chyba TTS: {e}")
            return None

    @staticmethod
    def transcribe_audio(audio_bytes):
        """
        P≈ôevede audio bytes na text.
        """
        r = sr.Recognizer()
        audio_file = io.BytesIO(audio_bytes)
        
        try:
            with sr.AudioFile(audio_file) as source:
                audio_data = r.record(source)
            text = r.recognize_google(audio_data, language=VOICE_LANG)
            return text
        except sr.UnknownValueError:
            return None
        except sr.RequestError as e:
            st.error(f"Chyba slu≈æby Speech API: {e}")
            return None
        except Exception as e:
            st.error(f"Chyba p≈ôepisu: {e}")
            return None

    @staticmethod
    def ask_gemini(prompt):
        """
        Komunikace s Google Gemini.
        """
        if not API_KEY:
            return "Chyb√≠ mi API kl√≠ƒç, nemohu odpov√≠dat."
            
        try:
            model = genai.GenerativeModel('gemini-1.5-flash')
            full_prompt = f"Odpovƒõz struƒçnƒõ, ƒçesky a k vƒõci jako finanƒçn√≠ asistent: {prompt}"
            response = model.generate_content(full_prompt)
            return response.text
        except Exception as e:
            return f"Chyba AI: {e}"

    @staticmethod
    def render_voice_ui():
        """
        Zobraz√≠ widget pro hlasov√© ovl√°d√°n√≠.
        """
        st.sidebar.markdown("---")
        st.sidebar.subheader("üéôÔ∏è Hlasov√Ω Asistent")
        
        # Nahr√°v√°n√≠
        audio_input = mic_recorder(
            start_prompt="üé§ Mluvit",
            stop_prompt="‚èπÔ∏è Stop",
            just_once=True,
            key='recorder_sidebar'
        )
        
        if audio_input:
            st.sidebar.info("Zpracov√°v√°m...")
            user_text = VoiceAssistant.transcribe_audio(audio_input['bytes'])
            
            if user_text:
                st.sidebar.write(f"üó£Ô∏è **Vy:** {user_text}")
                
                ai_response = VoiceAssistant.ask_gemini(user_text)
                st.sidebar.write(f"ü§ñ **AI:** {ai_response}")
                
                audio_html = VoiceAssistant.speak(ai_response)
                if audio_html:
                    st.sidebar.components.v1.html(audio_html, height=0)
            else:
                st.sidebar.warning("Nerozumƒõl jsem.")

# Testovac√≠ blok - spust√≠ se jen kdy≈æ zapne≈° p≈ô√≠mo tento soubor
if __name__ == "__main__":
    st.title("Test Voice Engine")
    VoiceAssistant.render_voice_ui()
